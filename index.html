<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="愿一切美好都能如约而至，喜欢的都能拥有"><meta name="keywords" content=""><meta name="author" content="wnxy"><meta name="copyright" content="wnxy"><title>Launch and learn. Everything is progress. | Wnxy's Blog</title><link rel="shortcut icon" href="/melody-favicon2.ico"><link rel="stylesheet" href="/css/index.css?version=1.7.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.7.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script>(adsbygoogle = window.adsbygoogle || []).push({
  google_ad_client: 'ca-pub-5336716665297879',
  enable_page_level_ads: 'true'
});
</script><link rel="dns-prefetch" href="https://hm.baidu.com"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8e5307dee6403f62f804e355d883fb17";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="Wnxy's Blog" type="application/atom+xml">
</head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="false"><div class="author-info"><div class="author-info__avatar text-center"><img src="https://s1.ax1x.com/2020/09/19/w5744e.jpg"></div><div class="author-info__name text-center">wnxy</div><div class="author-info__description text-center">愿一切美好都能如约而至，喜欢的都能拥有</div><div class="follow-button"><a href="https://github.com/wnxy" target="_blank" rel="noopener">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">30</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">44</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">10</span></a></div><hr><div class="twopeople"><div class="container" style="height:200px;"><canvas class="illo" width="800" height="800" style="max-width: 200px; max-height: 200px; touch-action: none; width: 640px; height: 640px;">      </canvas><script src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/twopeople1.js">     </script><script src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/zdog.dist.js">      </script><script id="rendered-js" src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/twopeople.js">      </script><style>.twopeople{
margin: 0;
align-items: center;
justify-content: center;
text-align: center;
}
canvas {
display: block;
margin: 0 auto;
cursor: move;
}</style></div></div></div></div><nav id="nav" style="background-image: url(https://api.ixiaowai.cn/gqapi/gqapi.php)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Wnxy's Blog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a><a class="site-page" href="/message">Message</a><a class="site-page" href="/links">Links</a><a class="site-page" href="/about">About</a><a class="site-page" href="/interest">Interest</a><a class="site-page" href="/clover">Clover</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> Search</span></a></span></div><div id="site-info"><div id="site-title">Wnxy's Blog</div><div id="site-sub-title">Launch and learn. Everything is progress.</div><div id="site-social-icons"><a class="social-icon" href="https://github.com/wnxy" target="_blank" rel="noreferrer noopener nofollow"><i class="fa-github fa"></i></a><a class="social-icon" href="https://weibo.com/u/6218442754?is_all=1" target="_blank" rel="noreferrer noopener nofollow"><i class="fa-weibo fa"></i></a><a class="social-icon" href="atom.xml" target="_blank" rel="noreferrer noopener nofollow"><i class="fa-rss fa"></i></a></div></div></nav><div id="content-outer"><div class="layout" id="content-inner"><div class="recent-post-item article-container"><a class="article-title" href="/2019/11/02/Python-100-days/">Python 100天</a><span class="article-meta"><i class="fa fa-thumb-tack article-meta__icon sticky"></i><span class="sticky">Sticky</span><span class="article-meta__separator" style="margin-right: 0.3rem">|</span></span><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-11-02</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Python/">Python</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Python/">Python</a></span><div class="content"><h3 id="【程序1】"><a href="#【程序1】" class="headerlink" title="【程序1】"></a>【程序1】</h3><p>题目：有1、2、3、4个数字，能组成多少个互不相同且无重复数字的三位数？都是多少？</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/11/10/Naive-bayes/">朴素贝叶斯算法原理及实现</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-11-10</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-Machine-Learning/">= 学习笔记 - Machine Learning</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Python/">Python</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Machine-Learning/">Machine-Learning</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/">朴素贝叶斯</a></span><div class="content"></div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/11/02/Data-visualization-matplotlib/">数据可视化模块Matplotlib实操</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-11-02</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Python/">Python</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Python/">Python</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Matplotlib/">Matplotlib</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/">数据可视化</a></span><div class="content"><p>通过 Matplotlib，开发者可以仅需要几行代码，便可以生成绘图，直方图，功率谱，条形图，错误图，散点图等。</p>
<h1 id="导读"><a href="#导读" class="headerlink" title="导读"></a><strong>导读</strong></h1><p>Matplotlib 是一个 Python 的 2D绘图库，它以各种硬拷贝格式和跨平台的交互式环境生成出版质量级别的图形。通过 Matplotlib，开发者可以仅需要几行代码，便可以生成绘图，直方图，功率谱，条形图，错误图，散点图等。</p>
<p>以下内容来自Github，为《PythonDataScienceHandbook[1]》(Python 数据科学手册[2])第四章Matplotlib介绍部分。全部内容都在以下环境演示通过：</p></div><a class="more" href="/2020/11/02/Data-visualization-matplotlib/#more">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/10/25/Neural-networks-realizes-MNIST-handwriting-recognition/">机器学习之神经网络实现MNIST手写字识别</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-10-25</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Machine-Learning/">Machine Learning</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Python/">Python</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Machine-Learning/">Machine-Learning</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/MNIST/">MNIST</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">神经网络</a></span><div class="content"><h2 id="一、神经网络原理"><a href="#一、神经网络原理" class="headerlink" title="一、神经网络原理"></a>一、神经网络原理</h2><p>线性回归（Linear Regression）和逻辑回归（Logistic Regression）通常用来处理线性模型，如果利用线性回归或逻辑回归对多特征的非线性问题进行分类，则涉及太多特征组合的计算，往往导致计算负荷增大，并不适合解决这类问题。</p>
<p>假设我们需要训练一个模型用来判断一张图片中是否出现汽车，可能有很多用来训练模型的数据，这些图片有的包含小汽车，有的没有，利用这些图片的一个个像素值作为特征，训练一个满足这样功能的模型。训练过程需要处理可能百万级别甚至更多的数据，对于这样问题通常采用神经网络（Neural Networks）解决。</p>
<h3 id="1-1-模型"><a href="#1-1-模型" class="headerlink" title="1.1 模型"></a>1.1 模型</h3><p><a href="https://imgchr.com/i/BQBHfO" target="_blank" rel="noopener"><img src="/loading.gif" data-original="https://s1.ax1x.com/2020/10/27/BQBHfO.png" alt=""></a></p>
<p>这个一个简单的3层神经网络，第一层为输入层（Input Layers），最后一层为输出层（Output Layers），中间层称为隐藏层（Hidden Layers）</p>
<h3 id="1-2-前向传播"><a href="#1-2-前向传播" class="headerlink" title="1.2 前向传播"></a>1.2 前向传播</h3><h4 id="1-2-1-激活函数"><a href="#1-2-1-激活函数" class="headerlink" title="1.2.1 激活函数"></a>1.2.1 激活函数</h4><p>（1）Sigmoid函数</p>
<p>一个常见的激活函数，其数学表达式为<a href="https://www.codecogs.com/eqnedit.php?latex=Sig(z)=\frac{1}{1&plus;e^{-z}}" target="_blank"><img src="/loading.gif" data-original="https://latex.codecogs.com/gif.latex?Sig(z)=\frac{1}{1&plus;e^{-z}}" title="Sig(z)=\frac{1}{1+e^{-z}}" /></a>。</p>
<p>Python实现代码为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span>+np.exp(-x))</span><br></pre></td></tr></table></figure>
<p>（2）ReLU函数</p>
<p>计算速度更快，是目前的主流激活函数。数学表达式为：<a href="https://www.codecogs.com/eqnedit.php?latex=ReLU(x)=\left\{\begin{matrix}&space;x&space;&&space;if&space;x>0\\&space;0&space;&&space;if&space;x\leq&space;0&space;\end{matrix}\right." target="_blank"><img src="/loading.gif" data-original="https://latex.codecogs.com/gif.latex?ReLU(x)=\left\{\begin{matrix}&space;x&space;&&space;if&space;x>0\\&space;0&space;&&space;if&space;x\leq&space;0&space;\end{matrix}\right." title="ReLU(x)=\left\{\begin{matrix} x & if x>0\\ 0 & if x\leq 0 \end{matrix}\right." /></a></p>
<p>Python实现代码为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.maximum(<span class="number">0</span>,x)</span><br></pre></td></tr></table></figure>
<h4 id="1-2-2-前向传播过程"><a href="#1-2-2-前向传播过程" class="headerlink" title="1.2.2 前向传播过程"></a>1.2.2 前向传播过程</h4><p>除输入层外，每一层神经元都有前一层的神经元作为本层神经元的输入，本层神经元的输出又可以作为下一层神经元的输入，依次向前传播最终得到一个输出值，这个由输入值经输入层经过一系列处理最终到达输出层得到输出值的过程称为前向传播。</p>
<p><a href="https://imgchr.com/i/B0npqA" target="_blank" rel="noopener"><img src="/loading.gif" data-original="https://s1.ax1x.com/2020/11/01/B0npqA.md.png" alt=""></a></p>
<p>其中x1, x2, x3是输入单元，即原始的输入数据，a1, a2, a3是中间单元，负责将输入的数据处理然后传递到下一层，最后是输出单元，负责计算<a href="https://www.codecogs.com/eqnedit.php?latex=h_{\Theta&space;}(x)" target="_blank"><img src="/loading.gif" data-original="https://latex.codecogs.com/gif.latex?h_{\Theta&space;}(x)" title="h_{\Theta }(x)" /></a>。计算的过程中为每一层都添加了一个偏置（bias unit）。</p>
<p>上图中<a href="https://www.codecogs.com/eqnedit.php?latex=\Theta&space;_{1}" target="_blank"><img src="/loading.gif" data-original="https://latex.codecogs.com/gif.latex?\Theta&space;_{1}" title="\Theta _{1}" /></a>，<a href="https://www.codecogs.com/eqnedit.php?latex=\Theta&space;_{2}" target="_blank"><img src="/loading.gif" data-original="https://latex.codecogs.com/gif.latex?\Theta&space;_{2}" title="\Theta _{2}" /></a>分别代表输入层到隐藏层的权重和隐藏层到输出层的权重，对于上图的网络模型激活单元和输出分别表达为：</p>
<p><a href="https://www.codecogs.com/eqnedit.php?latex=a_{1}^{(2)}=g(\Theta&space;_{10}^{(1)}x_{0}&plus;\Theta&space;_{11}^{(1)}x_{1}&plus;\Theta&space;_{12}^{(1)}x_{2}&plus;\Theta&space;_{13}^{(1)}x_{3})" target="_blank"><img src="/loading.gif" data-original="https://latex.codecogs.com/gif.latex?a_{1}^{(2)}=g(\Theta&space;_{10}^{(1)}x_{0}&plus;\Theta&space;_{11}^{(1)}x_{1}&plus;\Theta&space;_{12}^{(1)}x_{2}&plus;\Theta&space;_{13}^{(1)}x_{3})" title="a_{1}^{(2)}=g(\Theta _{10}^{(1)}x_{0}+\Theta _{11}^{(1)}x_{1}+\Theta _{12}^{(1)}x_{2}+\Theta _{13}^{(1)}x_{3})" /></a></p>
<p><a href="https://www.codecogs.com/eqnedit.php?latex=a_{2}^{(2)}=g(\Theta&space;_{20}^{(1)}x_{0}&plus;\Theta&space;_{21}^{(1)}x_{1}&plus;\Theta&space;_{22}^{(1)}x_{2}&plus;\Theta&space;_{23}^{(1)}x_{3})" target="_blank"><img src="/loading.gif" data-original="https://latex.codecogs.com/gif.latex?a_{2}^{(2)}=g(\Theta&space;_{20}^{(1)}x_{0}&plus;\Theta&space;_{21}^{(1)}x_{1}&plus;\Theta&space;_{22}^{(1)}x_{2}&plus;\Theta&space;_{23}^{(1)}x_{3})" title="a_{2}^{(2)}=g(\Theta _{20}^{(1)}x_{0}+\Theta _{21}^{(1)}x_{1}+\Theta _{22}^{(1)}x_{2}+\Theta _{23}^{(1)}x_{3})" /></a></p>
<p><a href="https://www.codecogs.com/eqnedit.php?latex=a_{3}^{(2)}=g(\Theta&space;_{30}^{(1)}x_{0}&plus;\Theta&space;_{31}^{(1)}x_{1}&plus;\Theta&space;_{32}^{(1)}x_{2}&plus;\Theta&space;_{33}^{(1)}x_{3})" target="_blank"><img src="/loading.gif" data-original="https://latex.codecogs.com/gif.latex?a_{3}^{(2)}=g(\Theta&space;_{30}^{(1)}x_{0}&plus;\Theta&space;_{31}^{(1)}x_{1}&plus;\Theta&space;_{32}^{(1)}x_{2}&plus;\Theta&space;_{33}^{(1)}x_{3})" title="a_{3}^{(2)}=g(\Theta _{30}^{(1)}x_{0}+\Theta _{31}^{(1)}x_{1}+\Theta _{32}^{(1)}x_{2}+\Theta _{33}^{(1)}x_{3})" /></a></p>
<p><a href="https://www.codecogs.com/eqnedit.php?latex=h_{\Theta&space;}(x)=g(\Theta&space;_{10}^{(2)}a_{0}^{(2)}&plus;\Theta&space;_{11}^{(2)}a_{1}^{(2)}&plus;\Theta&space;_{12}^{(2)}a_{2}^{(2)}&plus;\Theta&space;_{13}^{(2)}a_{3}^{(2)})" target="_blank"><img src="/loading.gif" data-original="https://latex.codecogs.com/gif.latex?h_{\Theta&space;}(x)=g(\Theta&space;_{10}^{(2)}a_{0}^{(2)}&plus;\Theta&space;_{11}^{(2)}a_{1}^{(2)}&plus;\Theta&space;_{12}^{(2)}a_{2}^{(2)}&plus;\Theta&space;_{13}^{(2)}a_{3}^{(2)})" title="h_{\Theta }(x)=g(\Theta _{10}^{(2)}a_{0}^{(2)}+\Theta _{11}^{(2)}a_{1}^{(2)}+\Theta _{12}^{(2)}a_{2}^{(2)}+\Theta _{13}^{(2)}a_{3}^{(2)})" /></a></p>
<p>如此，从左到右的算法称为前向传播算法，实际应用中为了计算方便通常是以矩阵方式计算的。</p>
<p>Python实现示例（示例不能直接运行）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self,X)</span>:</span></span><br><span class="line">    <span class="comment"># 前向传播算法forward_propagation，实现预测</span></span><br><span class="line">    self.a1 = X.T</span><br><span class="line">    self.z2 = np.dot(self.W1,self.a1)+self.b1</span><br><span class="line">    self.a2 = relu(self.z2)</span><br><span class="line">    self.z3 = np.dot(self.W2,self.a2)+self.b2</span><br><span class="line">    self.a3 = relu(self.z3)</span><br><span class="line">    out = self.a3</span><br><span class="line">    p = np.argmax(out, axis=<span class="number">0</span>)  <span class="comment"># 输出层的最大索引下标即为标签值，标签值0-9</span></span><br><span class="line">    <span class="keyword">return</span> p</span><br></pre></td></tr></table></figure>
<h3 id="1-3-代价函数"><a href="#1-3-代价函数" class="headerlink" title="1.3 代价函数"></a>1.3 代价函数</h3><p><a href="https://imgchr.com/i/B0M4F1" target="_blank" rel="noopener"><img src="/loading.gif" data-original="https://s1.ax1x.com/2020/11/01/B0M4F1.md.png" alt=""></a></p>
<p>通过代价函数观察预测的结果与真实情况的误差有多大。</p>
<h3 id="1-4-反向传播算法"><a href="#1-4-反向传播算法" class="headerlink" title="1.4 反向传播算法"></a>1.4 反向传播算法</h3><p>一般的训练算法可以分为两个阶段：</p>
<p>（1）求解代价函数关于权值（参数）的导数。（BP）</p>
<p>（2）用得到的导数进一步计算权值的调整量。（梯度下降等优化算法）</p>
<p>反向传播（BP）算法主要应用第一阶段,非常高效的计算这些导数。</p>
<h4 id="1-4-1-推导过程"><a href="#1-4-1-推导过程" class="headerlink" title="1.4.1 推导过程"></a>1.4.1 推导过程</h4><p>假设有一个四层的神经网络，其相关参数为： Sl=4, L=4（其中L表示网络层数，Sl表示l层有多少个神经元），用<a href="https://www.codecogs.com/eqnedit.php?latex=\sigma" target="_blank"><img src="/loading.gif" data-original="https://latex.codecogs.com/gif.latex?\sigma" title="\sigma" /></a>表示误差，结合前面介绍的前向传播过程，则：</p>
<p><a href="https://www.codecogs.com/eqnedit.php?latex=\sigma&space;^{(4)}=a^{(4)}-y" target="_blank"><img src="/loading.gif" data-original="https://latex.codecogs.com/gif.latex?\sigma&space;^{(4)}=a^{(4)}-y" title="\sigma ^{(4)}=a^{(4)}-y" /></a></p>
<p>前一层误差为：<a href="https://www.codecogs.com/eqnedit.php?latex=\sigma&space;^{(3)}=(\Theta&space;^{(3)})^{T}\sigma&space;^{(4)}*g^{'}(z^{(2)})" target="_blank"><img src="/loading.gif" data-original="https://latex.codecogs.com/gif.latex?\sigma&space;^{(3)}=(\Theta&space;^{(3)})^{T}\sigma&space;^{(4)}*g^{'}(z^{(2)})" title="\sigma ^{(3)}=(\Theta ^{(3)})^{T}\sigma ^{(4)}*g^{'}(z^{(3)})" /></a></p>
<p>其中<a href="https://www.codecogs.com/eqnedit.php?latex=g^{'}(z^{(2)})" target="_blank"><img src="/loading.gif" data-original="https://latex.codecogs.com/gif.latex?g^{'}(z^{(2)})" title="g^{'}(z^{(2)})" /></a>是Sig函数的导数。</p>
<p>接着第二层的误差为：<a href="https://www.codecogs.com/eqnedit.php?latex=\sigma&space;^{(2)}=(\Theta&space;^{(2)})^{T}\sigma&space;^{(3)}*g^{'}(z^{(2)})" target="_blank"><img src="/loading.gif" data-original="https://latex.codecogs.com/gif.latex?\sigma&space;^{(2)}=(\Theta&space;^{(2)})^{T}\sigma&space;^{(3)}*g^{'}(z^{(2)})" title="\sigma ^{(2)}=(\Theta ^{(2)})^{T}\sigma ^{(3)}*g^{'}(z^{(2)})" /></a></p>
<p>第一层是输入变量，不存在误差，此时不考虑正则项，则有：<a href="https://www.codecogs.com/eqnedit.php?latex=\frac{\partial&space;}{\partial&space;\Theta&space;_{ij}^{(l)}}J(\Theta&space;)=a_{ij}^{(l)}\sigma&space;_{i}^{l&plus;1}" target="_blank"><img src="/loading.gif" data-original="https://latex.codecogs.com/gif.latex?\frac{\partial&space;}{\partial&space;\Theta&space;_{ij}^{(l)}}J(\Theta&space;)=a_{ij}^{(l)}\sigma&space;_{i}^{l&plus;1}" title="\frac{\partial }{\partial \Theta _{ij}^{(l)}}J(\Theta )=a_{ij}^{(l)}\sigma _{i}^{l+1}" /></a></p>
<p>要求的导数 = 权值输出端单元的误差项 * 权值输入端单元的激活值。</p>
<p>Python实现示例（示例不能直接运行）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#反向传播：</span></span><br><span class="line"><span class="comment">#1、m表示样本个数</span></span><br><span class="line"><span class="comment">#2、梯度下降，更新W和b</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self, dAL)</span>:</span></span><br><span class="line">    m=<span class="number">60000</span></span><br><span class="line">    dZ3=np.multiply(dAL,relu_derivative(self.z3))</span><br><span class="line">    dW2=np.dot(dZ3, self.a2.T)/m</span><br><span class="line">    db2=np.mean(dZ3,axis=<span class="number">1</span>)</span><br><span class="line">    dAL_1 = np.dot(self.W2.T, dZ3)</span><br><span class="line">    dZ2 = np.multiply(dAL_1, relu_derivative(self.z2))</span><br><span class="line">    dW1 = np.dot(dZ2, self.a1.T) / m</span><br><span class="line">    db1 = np.mean(dZ2, axis=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 更新权值</span></span><br><span class="line">    self.W2-=self.lr*dW2</span><br><span class="line">    self.b2-=self.lr*db2</span><br><span class="line">    self.W1 -= self.lr * dW1</span><br><span class="line">    self.b1 -= self.lr * db1</span><br></pre></td></tr></table></figure>
<h2 id="二、数据集解析"><a href="#二、数据集解析" class="headerlink" title="二、数据集解析"></a>二、数据集解析</h2><p>数据集来源：<a href="http://yann.lecun.com/exdb/mnist，选用MNIST手写字数据集训练神经网络，数据集使用Python模块Struct解析二进制文件。手写字特征为28*28=784个像素点，输出为手写字值。解析过程不做详细介绍，其数据解析的一种Python实现为：" target="_blank" rel="noopener">http://yann.lecun.com/exdb/mnist，选用MNIST手写字数据集训练神经网络，数据集使用Python模块Struct解析二进制文件。手写字特征为28*28=784个像素点，输出为手写字值。解析过程不做详细介绍，其数据解析的一种Python实现为：</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> struct</span><br><span class="line"></span><br><span class="line">file1=<span class="string">"./MNIST_data/train-images.idx3-ubyte"</span></span><br><span class="line">file2=<span class="string">"./MNIST_data/train-labels.idx1-ubyte"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_images_ana</span><span class="params">(filepath)</span>:</span></span><br><span class="line">    <span class="string">"""解析图片数据集 .idx3-ubyte格式"""</span></span><br><span class="line">    <span class="comment"># 以二进制方式读取文件</span></span><br><span class="line">    <span class="keyword">with</span> open(filepath,<span class="string">'rb'</span>) <span class="keyword">as</span> fbj:</span><br><span class="line">        bin_data=fbj.read()</span><br><span class="line">    offset=<span class="number">0</span></span><br><span class="line">    magic_num,image_num,rows_num,column_num=struct.unpack_from(<span class="string">'&gt;iiii'</span>,bin_data,offset)</span><br><span class="line">    offset+=struct.calcsize(<span class="string">'&gt;iiii'</span>)</span><br><span class="line">    imgsize=image_num*rows_num*column_num</span><br><span class="line">    fmt_image=<span class="string">'&gt;'</span>+str(imgsize)+<span class="string">'B'</span>      <span class="comment"># 训练集数据有60000*28*28</span></span><br><span class="line">    images=struct.unpack_from(fmt_image,bin_data,offset)</span><br><span class="line">    img=np.reshape(images,(image_num,rows_num*column_num))     <span class="comment"># 构造一个60000*784的矩阵</span></span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_labels_ana</span><span class="params">(filepath)</span>:</span></span><br><span class="line">    <span class="string">"""解析特征数据集 .idx1-ubyte格式"""</span></span><br><span class="line">    <span class="comment"># 以二进制格式处理文件</span></span><br><span class="line">    <span class="keyword">with</span> open(filepath,<span class="string">'rb'</span>) <span class="keyword">as</span> fbj:</span><br><span class="line">        bin_data=fbj.read()</span><br><span class="line">    offset=<span class="number">0</span></span><br><span class="line">    magic_num,items_num=struct.unpack_from(<span class="string">'&gt;ii'</span>,bin_data,offset)</span><br><span class="line">    offset+=struct.calcsize(<span class="string">'&gt;ii'</span>)</span><br><span class="line">    fmt_label=<span class="string">'&gt;'</span>+str(items_num)+<span class="string">'B'</span></span><br><span class="line">    labels=struct.unpack_from(fmt_label,bin_data,offset)</span><br><span class="line">    label=np.reshape(labels,[items_num])</span><br><span class="line">    <span class="keyword">return</span> label</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    imgs=train_images_ana(file1)</span><br><span class="line">    print(np.shape(imgs[<span class="number">1</span>]))</span><br><span class="line">    labels = train_labels_ana(file2)</span><br><span class="line">    print(labels)</span><br><span class="line">    print(np.shape(labels[<span class="number">1</span>]))</span><br><span class="line">    <span class="comment"># 查看前10个手写字灰度图</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        img=np.reshape(imgs[i],[<span class="number">28</span>,<span class="number">28</span>])</span><br><span class="line">        plt.imshow(img,cmap=<span class="string">'gray'</span>)</span><br><span class="line">        print(labels[i])</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="三、神经网络搭建"><a href="#三、神经网络搭建" class="headerlink" title="三、神经网络搭建"></a>三、神经网络搭建</h2><p>搭建一个三层神经网络，输入层、隐藏层、输出层节点分别为：784，100，10。</p>
<h2 id="四、附录"><a href="#四、附录" class="headerlink" title="四、附录"></a>四、附录</h2><p>network.py文件，构建神经网络类。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> activation_func <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> loss <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Network</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,inputnodes,hidnodes,outputnodes,learning_rate)</span>:</span></span><br><span class="line">        self.innodes = inputnodes</span><br><span class="line">        self.hidnodes = hidnodes</span><br><span class="line">        self.outnodes = outputnodes</span><br><span class="line">        self.lr = learning_rate</span><br><span class="line">        <span class="comment">#各层权重 偏置</span></span><br><span class="line">        self.W1 = np.random.randn(self.hidnodes, self.innodes) * <span class="number">0.01</span></span><br><span class="line">        self.W2 = np.random.randn(self.outnodes, self.hidnodes) * <span class="number">0.01</span></span><br><span class="line">        self.b1 = np.random.randn(self.hidnodes, <span class="number">1</span>) * <span class="number">0.01</span></span><br><span class="line">        self.b2 = np.random.randn(self.outnodes, <span class="number">1</span>) * <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self,X)</span>:</span></span><br><span class="line">        <span class="comment"># 前向传播算法forward_propagation，实现预测</span></span><br><span class="line">        self.a1 = X.T</span><br><span class="line">        self.z2 = np.dot(self.W1,self.a1)+self.b1</span><br><span class="line">        self.a2 = relu(self.z2)</span><br><span class="line">        self.z3 = np.dot(self.W2,self.a2)+self.b2</span><br><span class="line">        self.a3 = relu(self.z3)</span><br><span class="line">        out = self.a3</span><br><span class="line">        p = np.argmax(out, axis=<span class="number">0</span>)  <span class="comment"># 输出层的最大索引下标即为标签值，标签值0-9</span></span><br><span class="line">        <span class="keyword">return</span> p</span><br><span class="line"></span><br><span class="line">    <span class="comment">#反向传播：</span></span><br><span class="line">    <span class="comment">#1、m表示样本个数</span></span><br><span class="line">    <span class="comment">#2、梯度下降，更新W和b</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self, dAL)</span>:</span></span><br><span class="line">        m=<span class="number">60000</span></span><br><span class="line">        dZ3=np.multiply(dAL,relu_derivative(self.z3))</span><br><span class="line">        dW2=np.dot(dZ3, self.a2.T)/m</span><br><span class="line">        db2=np.mean(dZ3,axis=<span class="number">1</span>)</span><br><span class="line">        dAL_1 = np.dot(self.W2.T, dZ3)</span><br><span class="line">        dZ2 = np.multiply(dAL_1, relu_derivative(self.z2))</span><br><span class="line">        dW1 = np.dot(dZ2, self.a1.T) / m</span><br><span class="line">        db1 = np.mean(dZ2, axis=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 梯度下降</span></span><br><span class="line">        self.W2-=self.lr*dW2</span><br><span class="line">        self.b2-=self.lr*db2</span><br><span class="line">        self.W1 -= self.lr * dW1</span><br><span class="line">        self.b1 -= self.lr * db1</span><br></pre></td></tr></table></figure>
<p>loss.py文件，损失函数计算代价。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#交叉熵损失函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cross_entropy</span><span class="params">(y, y_predict)</span>:</span></span><br><span class="line">    y_predict = np.clip(y_predict,<span class="number">1e-10</span>,<span class="number">1</span><span class="number">-1e-10</span>) <span class="comment">#防止0*log(0)出现。导致计算结果变为NaN</span></span><br><span class="line">    <span class="keyword">return</span> -(y * np.log(y_predict) + (<span class="number">1</span> - y) * np.log(<span class="number">1</span> - y_predict))</span><br><span class="line"></span><br><span class="line"><span class="comment">#交叉熵损失函数的导函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cross_entropy_der</span><span class="params">(y,y_predict)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> -y/y_predict+(<span class="number">1</span>-y)/(<span class="number">1</span>-y_predict)</span><br></pre></td></tr></table></figure>
<p>activation.py文件，激活函数及其导数实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">    激活函数</span></span><br><span class="line"><span class="string">    选择非线性的激活函数处理非线性假设</span></span><br><span class="line"><span class="string">    常用激活函数relu、sigmoid</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span>+np.exp(-x))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.maximum(<span class="number">0</span>,x)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sig_derivative</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="comment">#sig函数求导</span></span><br><span class="line">    fx=sigmoid(x)</span><br><span class="line">    <span class="keyword">return</span> fx*(<span class="number">1</span>-fx)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu_derivative</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> (x&gt;=<span class="number">0</span>).astype(np.float64)</span><br></pre></td></tr></table></figure>
<p>load_data.py文件，加载数据集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> struct</span><br><span class="line"></span><br><span class="line">file1=<span class="string">"./MNIST_data/train-images.idx3-ubyte"</span></span><br><span class="line">file2=<span class="string">"./MNIST_data/train-labels.idx1-ubyte"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_images_ana</span><span class="params">(filepath)</span>:</span></span><br><span class="line">    <span class="string">"""解析图片数据集 .idx3-ubyte格式"""</span></span><br><span class="line">    <span class="comment"># 以二进制方式读取文件</span></span><br><span class="line">    <span class="keyword">with</span> open(filepath,<span class="string">'rb'</span>) <span class="keyword">as</span> fbj:</span><br><span class="line">        bin_data=fbj.read()</span><br><span class="line"></span><br><span class="line">    offset=<span class="number">0</span></span><br><span class="line">    magic_num,image_num,rows_num,column_num=struct.unpack_from(<span class="string">'&gt;iiii'</span>,bin_data,offset)</span><br><span class="line">    offset+=struct.calcsize(<span class="string">'&gt;iiii'</span>)</span><br><span class="line">    imgsize=image_num*rows_num*column_num</span><br><span class="line">    fmt_image=<span class="string">'&gt;'</span>+str(imgsize)+<span class="string">'B'</span>      <span class="comment"># 训练集数据有60000*28*28</span></span><br><span class="line">    images=struct.unpack_from(fmt_image,bin_data,offset)</span><br><span class="line">    img=np.reshape(images,(image_num,rows_num*column_num))     <span class="comment"># 构造一个60000*784的矩阵</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="comment">#print(magic_num,image_num,rows_num,column_num)</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_labels_ana</span><span class="params">(filepath)</span>:</span></span><br><span class="line">    <span class="string">"""解析特征数据集 .idx1-ubyte格式"""</span></span><br><span class="line">    <span class="comment"># 以二进制格式处理文件</span></span><br><span class="line">    <span class="keyword">with</span> open(filepath,<span class="string">'rb'</span>) <span class="keyword">as</span> fbj:</span><br><span class="line">        bin_data=fbj.read()</span><br><span class="line"></span><br><span class="line">    offset=<span class="number">0</span></span><br><span class="line">    magic_num,items_num=struct.unpack_from(<span class="string">'&gt;ii'</span>,bin_data,offset)</span><br><span class="line">    offset+=struct.calcsize(<span class="string">'&gt;ii'</span>)</span><br><span class="line">    fmt_label=<span class="string">'&gt;'</span>+str(items_num)+<span class="string">'B'</span></span><br><span class="line">    labels=struct.unpack_from(fmt_label,bin_data,offset)</span><br><span class="line">    label=np.reshape(labels,[items_num])</span><br><span class="line">    <span class="keyword">return</span> label</span><br></pre></td></tr></table></figure>
<p>train.py文件，训练模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> network <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> load_data <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">input_nodes = <span class="number">784</span></span><br><span class="line">hidden_nodes = <span class="number">100</span></span><br><span class="line">output_nodes = <span class="number">10</span></span><br><span class="line">learning_rate = <span class="number">0.1</span></span><br><span class="line">n = Network(input_nodes, hidden_nodes, output_nodes, learning_rate)</span><br><span class="line"></span><br><span class="line">X=train_images_ana(file1)</span><br><span class="line">Y=train_labels_ana(file2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练神经网络</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    cnt = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">60000</span>):</span><br><span class="line">        Y_predict = n.predict(np.mat(X[i]))</span><br><span class="line">        <span class="keyword">if</span> (Y[i]==Y_predict):</span><br><span class="line">            cnt+=<span class="number">1</span></span><br><span class="line">        dA = cross_entropy_der(np.mat(Y[i]),Y_predict)</span><br><span class="line">        n.backward(dA)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'epoch %d:accurac=%f'</span>%(epoch,cnt/<span class="number">60000</span>))</span><br></pre></td></tr></table></figure>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/10/19/Logistic-regression-realizes-MNIST-handwriting-recognition/">机器学习之逻辑回归实现MNIST手写字识别</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-10-19</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Machine-Learning/">Machine Learning</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Python/">Python</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Machine-Learning/">Machine-Learning</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/">逻辑回归</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/MNIST/">MNIST</a></span><div class="content"></div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/10/18/Data-analysis-of-MNIST-handwritten-character-set/">MNIST手写字符集的数据解析</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-10-18</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Machine-Learning/">Machine Learning</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Python/">Python</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Machine-Learning/">Machine-Learning</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%90/">数据解析</a></span><div class="content"><h3 id="1-前言"><a href="#1-前言" class="headerlink" title="1.前言"></a>1.前言</h3><p>最近在做MNIST手写字识别，官方MNIST数据集为 .idx3-ubyte 格式，程序无法直接读取，涉及MNIST数据集的解析。</p>
<p>MNIST数据集：<a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="noopener">http://yann.lecun.com/exdb/mnist/</a></p></div><a class="more" href="/2020/10/18/Data-analysis-of-MNIST-handwritten-character-set/#more">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/10/17/Daily-usage-of-Struct-module-in-Python/">Python中Struct模块的日常用法</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-10-17</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Python/">Python</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Python/">Python</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Struct%E6%A8%A1%E5%9D%97/">Struct模块</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%A4%84%E7%90%86/">二进制处理</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Binary/">Binary</a></span><div class="content"><p><strong>最近在训练mnist字符集时用到二进制数据的处理，面向Google编程后稍稍搞懂了一点，故做一点笔记，以作备忘。</strong></p>
<p>Python 中用来处理二进制数据时采用 Struct 模块。</p>
<p>Struct模块中最常用的函数为:</p></div><a class="more" href="/2020/10/17/Daily-usage-of-Struct-module-in-Python/#more">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/10/11/Machine-learning-logistic-regression-algorithm/">机器学习——逻辑回归算法（Logistic Regression）思想及算法实现</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-10-11</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Machine-Learning/">Machine Learning</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Python/">Python</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Machine-Learning/">Machine-Learning</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><div class="content"><h1 id="1-分类原理"><a href="#1-分类原理" class="headerlink" title="1.分类原理"></a>1.分类原理</h1><h2 id="1-1-逻辑回归"><a href="#1-1-逻辑回归" class="headerlink" title="1.1 逻辑回归"></a>1.1 逻辑回归</h2><p>逻辑回归算法是一个分类算法，其性质是它的输出值永远在0到1之间，是目前最流行、最广泛使用的一直学习算法。</p>
<h2 id="1-2-Sigmoid函数"><a href="#1-2-Sigmoid函数" class="headerlink" title="1.2 Sigmoid函数"></a>1.2 Sigmoid函数</h2><p>根据线性回归模型我们只能预测连续的值，然而对于分类问题，我们需要输出0或1，此时引入逻辑回归模型，模型核心为Sigmoid函数，公式为：$g(z)=\frac{1}{1+e^{-z}}$</p>
<p>其中：$z=-\Theta^{T} X$</p></div><a class="more" href="/2020/10/11/Machine-learning-logistic-regression-algorithm/#more">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/10/09/Python-data-visualization/">python数据可视化——函数图像绘制</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-10-09</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Python/">Python</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Python/">Python</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Machine-Learning/">Machine-Learning</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Matplotlib/">Matplotlib</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E5%87%BD%E6%95%B0%E5%9B%BE%E5%83%8F/">函数图像</a></span><div class="content"><p>利用python的matplotlib库进行数据可视化，绘制定义函数的图像。</p>
<p>以机器学习逻辑回归的sigmoid函数为例：</p>
<p><a href="https://www.codecogs.com/eqnedit.php?latex=g\left&space;(&space;z&space;\right&space;)=\frac{1}{1&plus;e^{-z}}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?g\left&space;(&space;z&space;\right&space;)=\frac{1}{1&plus;e^{-z}}" title="g\left ( z \right )=\frac{1}{1+e^{-z}}" /></a></p>
<p>python代码实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义sigmoid函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(z)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span>+np.exp(-z))</span><br></pre></td></tr></table></figure></div><a class="more" href="/2020/10/09/Python-data-visualization/#more">Read more</a><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/09/19/Hexo-melody-blog-beautification1/">hexo melody博客不蒜子统计无法显示问题解决</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-09-19</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/Hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/">Hexo博客搭建</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/hexo/">hexo</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/melody/">melody</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/%E5%8D%9A%E5%AE%A2%E7%BE%8E%E5%8C%96/">博客美化</a></span><div class="content"><p>参考文章：<a href="https://www.jianshu.com/p/0befb34dce16" target="_blank" rel="noopener">https://www.jianshu.com/p/0befb34dce16</a></p>
<p>存在问题：已发布的hexo melody主题博客不蒜子统计不能显示</p>
<p>解决：修改\themes\melody\layout\includes\count路径下busuanzi.pug文件</p></div><a class="more" href="/2020/09/19/Hexo-melody-blog-beautification1/#more">Read more</a><hr></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(https://api.ixiaowai.cn/gqapi/gqapi.php)"><div class="layout" id="footer"><div class="copyright">&copy;2017 - 2020 By wnxy</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span><span></span></span><span class="footer-separator">|</span><span><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.7.0"></script><script src="/js/fancybox.js?version=1.7.0"></script><script src="/js/sidebar.js?version=1.7.0"></script><script src="/js/copy.js?version=1.7.0"></script><script src="/js/fireworks.js?version=1.7.0"></script><script src="/js/transition.js?version=1.7.0"></script><script src="/js/scroll.js?version=1.7.0"></script><script src="/js/head.js?version=1.7.0"></script><script src="https://cdn.jsdelivr.net/gh/xiabo2/CDN@latest/fish.js?version=1.7.0"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="/js/search/local-search.js"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div><script type="text/javascript" src="/js/crash_cheat.js"></script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"jsonPath":"live2d-widget-model-koharu"},"display":{"superSample":2,"width":210,"height":420,"position":"right","hOffset":0,"vOffset":-20},"log":false,"tagMode":false});</script><script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script><script>!function(n){n.imageLazyLoadSetting.processImages=o;var i=n.imageLazyLoadSetting.isSPA,r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function o(){i&&(r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")));for(var a=0;a<r.length;a++)t=r[a],0<=(e=t.getBoundingClientRect()).bottom&&0<=e.left&&e.top<=(n.innerHeight||document.documentElement.clientHeight)&&function(){var t,e,n,i,o=r[a];t=o,e=function(){r=r.filter(function(t){return o!==t})},n=new Image,i=t.getAttribute("data-original"),n.onload=function(){t.src=i,e&&e()},n.src=i}();var t,e}o(),n.addEventListener("scroll",function(){var t,e;t=o,e=n,clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(e)},500)})}(this);</script><script>'use strict';'serviceWorker'in navigator&&navigator.serviceWorker.register('service-worker.js').then(function(a){a.onupdatefound=function(){var b=a.installing;b.onstatechange=function(){switch(b.state){case'installed':navigator.serviceWorker.controller?console.log('New or updated content is available.'):console.log('Content is now available offline!');break;case'redundant':console.error('The installing service worker became redundant.');}}}}).catch(function(a){console.error('Error during service worker registration:',a)});
</script></body></html>